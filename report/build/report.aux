\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Variable Density Random Undersampling Pattern Generation and Aliasing Artifacts Analysis}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Undersampling Pattern Generation}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Undersampling Masks Plotting}{2}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Undersampling Mask for one dynamic frame and undersampling masks in the ky-t dimension.}}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:undersampling_mask}{{1}{2}{Undersampling Mask for one dynamic frame and undersampling masks in the ky-t dimension}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Multiple sampling masks showing the variable density patterns across different temporal frames.}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:multiple_masks}{{2}{3}{Multiple sampling masks showing the variable density patterns across different temporal frames}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Aliased Images Depiction and Comparison}{3}{subsection.2.3}\protected@file@percent }
\newlabel{fig:comparison_image_0}{{3a}{4}{Comparison for frame 0}{figure.caption.4}{}}
\newlabel{sub@fig:comparison_image_0}{{a}{4}{Comparison for frame 0}{figure.caption.4}{}}
\newlabel{fig:comparison_image_1}{{3b}{4}{Comparison for frame 1}{figure.caption.4}{}}
\newlabel{sub@fig:comparison_image_1}{{b}{4}{Comparison for frame 1}{figure.caption.4}{}}
\newlabel{fig:comparison_image_2}{{3c}{4}{Comparison for frame 2}{figure.caption.4}{}}
\newlabel{sub@fig:comparison_image_2}{{c}{4}{Comparison for frame 2}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison between fully sampled (left), undersampled (middle), and corresponding sampling mask (right) for different frames.}}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:comparison_images}{{3}{4}{Comparison between fully sampled (left), undersampled (middle), and corresponding sampling mask (right) for different frames}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Dataset Partition, Denoising Network Construction and Evaluation}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset Partition}{5}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}CNN Network Designing and Training}{5}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Overall architecture of our proposed reconstruction network with dual UNet branches for real and imaginary components and 3D ResNet for temporal fusion.}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:pipeline}{{4}{5}{Overall architecture of our proposed reconstruction network with dual UNet branches for real and imaginary components and 3D ResNet for temporal fusion}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Training Loss and Validation Loss (No Dropout/Dynamic LR)}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:loss_no_opt}{{5}{6}{Training Loss and Validation Loss (No Dropout/Dynamic LR)}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Fully Sampled Images (Ground Truth)}}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:full_sampled_no_opt}{{6}{6}{Fully Sampled Images (Ground Truth)}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Under Sampled Images (Input to Network)}}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:under_sampled_no_opt}{{7}{6}{Under Sampled Images (Input to Network)}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Reconstruction Images (Baseline Model - No Dropout/Dynamic LR)}}{6}{figure.caption.9}\protected@file@percent }
\newlabel{fig:reconstructed_no_opt}{{8}{6}{Reconstruction Images (Baseline Model - No Dropout/Dynamic LR)}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Quantitative Evaluation (Baseline Model)}{7}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Impact of Dropout and Dynamic Learning Rate}{7}{section.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Compare PSNR and SSIM with and without Dropout/Dynamic LR}}{7}{table.caption.10}\protected@file@percent }
\newlabel{tab:opt_compare}{{1}{7}{Compare PSNR and SSIM with and without Dropout/Dynamic LR}{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Training Loss and Validation Loss (Optimized Model with Dropout/Dynamic LR, L2 Loss)}}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:loss_opt}{{9}{8}{Training Loss and Validation Loss (Optimized Model with Dropout/Dynamic LR, L2 Loss)}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Compare L1 with L2 Loss}{8}{section.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Compare PSNR and SSIM with L1 vs L2 Loss (Optimized Model)}}{8}{table.caption.12}\protected@file@percent }
\newlabel{tab:loss_compare}{{2}{8}{Compare PSNR and SSIM with L1 vs L2 Loss (Optimized Model)}{table.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Training Loss and Validation Loss (Optimized Model with L1 Loss)}}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:loss_l1}{{10}{9}{Training Loss and Validation Loss (Optimized Model with L1 Loss)}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Application of Perceptual Loss and Edge Loss in MRI Reconstruction}{9}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Unrolled Deep Learning Reconstruction Network}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Training Details and Results}{10}{subsection.6.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of Original and Unrolled Networks}}{10}{table.caption.14}\protected@file@percent }
\newlabel{tab:unrolled_compare}{{3}{10}{Comparison of Original and Unrolled Networks}{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Training and Validation Loss Curves for the 3-Cascade Unrolled Network}}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:loss_unrolled}{{11}{10}{Training and Validation Loss Curves for the 3-Cascade Unrolled Network}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Discussion}{11}{subsection.6.2}\protected@file@percent }
\gdef \@abspage@last{11}
